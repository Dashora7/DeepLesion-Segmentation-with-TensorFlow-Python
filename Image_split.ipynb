{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.count of                   File_name Image_size  Possibly_noisy  Train_Val_Test\n",
      "0      000001_01_01_109.png   512, 512             0.0             3.0\n",
      "1      000001_02_01_014.png   512, 512             0.0             3.0\n",
      "2      000001_02_01_017.png   512, 512             0.0             3.0\n",
      "3      000001_03_01_088.png   512, 512             0.0             3.0\n",
      "4      000001_04_01_017.png   512, 512             0.0             3.0\n",
      "5      000002_01_01_162.png   512, 512             0.0             2.0\n",
      "6      000002_01_01_176.png   512, 512             0.0             2.0\n",
      "7      000002_02_01_077.png   512, 512             0.0             2.0\n",
      "8      000002_02_01_050.png   512, 512             0.0             2.0\n",
      "9      000002_02_01_065.png   512, 512             0.0             2.0\n",
      "10     000002_02_01_052.png   512, 512             0.0             2.0\n",
      "11     000002_03_01_041.png   512, 512             0.0             2.0\n",
      "12     000003_01_01_016.png   512, 512             0.0             1.0\n",
      "13     000004_01_01_007.png   512, 512             0.0             2.0\n",
      "14     000004_02_01_013.png   512, 512             0.0             2.0\n",
      "15     000004_02_02_073.png   512, 512             0.0             2.0\n",
      "16     000004_02_02_145.png   512, 512             0.0             2.0\n",
      "17     000004_03_01_008.png   512, 512             0.0             2.0\n",
      "18     000004_03_02_136.png   512, 512             0.0             2.0\n",
      "19     000005_01_01_052.png   512, 512             0.0             1.0\n",
      "20     000006_01_01_062.png   512, 512             0.0             1.0\n",
      "21     000006_02_01_062.png   512, 512             0.0             1.0\n",
      "22     000007_01_01_173.png   512, 512             0.0             1.0\n",
      "23     000007_02_01_073.png   512, 512             0.0             1.0\n",
      "24     000007_03_01_057.png   512, 512             0.0             1.0\n",
      "25     000007_03_01_052.png   512, 512             0.0             1.0\n",
      "26     000007_03_02_066.png   512, 512             0.0             1.0\n",
      "27     000008_01_01_033.png   512, 512             0.0             1.0\n",
      "28     000008_02_01_751.png   512, 512             0.0             1.0\n",
      "29     000008_02_01_641.png   512, 512             0.0             1.0\n",
      "...                     ...        ...             ...             ...\n",
      "32670  004447_01_01_349.png   512, 512             0.0             1.0\n",
      "32671  004448_01_01_042.png   512, 512             0.0             1.0\n",
      "32672  004448_01_02_231.png   512, 512             0.0             1.0\n",
      "32673  004449_01_01_030.png   512, 512             0.0             1.0\n",
      "32674  004450_01_01_025.png   512, 512             0.0             1.0\n",
      "32675  004450_01_01_030.png   512, 512             0.0             1.0\n",
      "32676  004450_01_01_026.png   512, 512             0.0             1.0\n",
      "32677  004450_01_01_070.png   512, 512             0.0             1.0\n",
      "32678  004450_01_01_066.png   512, 512             0.0             1.0\n",
      "32679  004450_01_01_084.png   512, 512             0.0             1.0\n",
      "32680  004450_01_02_119.png   512, 512             0.0             1.0\n",
      "32681  004451_01_01_140.png   512, 512             0.0             1.0\n",
      "32682  004451_01_01_149.png   512, 512             0.0             1.0\n",
      "32683  004453_01_01_132.png   512, 512             0.0             1.0\n",
      "32684  004454_01_01_116.png   512, 512             0.0             2.0\n",
      "32685  004455_01_01_105.png   512, 512             0.0             2.0\n",
      "32686  004455_01_02_113.png   512, 512             0.0             2.0\n",
      "32687  004456_01_01_024.png   512, 512             0.0             1.0\n",
      "32688  004457_01_01_037.png   512, 512             0.0             1.0\n",
      "32689  004458_01_01_005.png   512, 512             0.0             1.0\n",
      "32690  004458_01_01_004.png   512, 512             0.0             1.0\n",
      "32691  004458_01_01_060.png   512, 512             0.0             1.0\n",
      "32692  004458_01_01_076.png   512, 512             0.0             1.0\n",
      "32693  004458_01_01_046.png   512, 512             0.0             1.0\n",
      "32694  004458_01_01_065.png   512, 512             0.0             1.0\n",
      "32695  004458_01_01_059.png   512, 512             0.0             1.0\n",
      "32696  004458_01_01_049.png   512, 512             0.0             1.0\n",
      "32697  004458_01_01_047.png   512, 512             0.0             1.0\n",
      "32698  004458_01_01_102.png   512, 512             0.0             1.0\n",
      "32699  004459_01_01_051.png   512, 512             0.0             1.0\n",
      "\n",
      "[32700 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\annotations\\\\info.csv\", usecols = [\"File_name\", \"Possibly_noisy\", \"Train_Val_Test\", \"Image_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "117\n",
      "118\n",
      "128\n",
      "146\n",
      "659\n",
      "660\n",
      "3726\n",
      "3727\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3957\n",
      "5015\n",
      "6679\n",
      "6680\n",
      "7801\n",
      "8620\n",
      "11038\n",
      "11077\n",
      "11078\n",
      "11079\n",
      "11080\n",
      "11081\n",
      "11082\n",
      "11083\n",
      "11236\n",
      "11237\n",
      "11238\n",
      "11338\n",
      "11339\n",
      "16660\n",
      "18294\n",
      "18692\n",
      "19063\n",
      "19957\n",
      "22598\n",
      "22599\n",
      "22600\n"
     ]
    }
   ],
   "source": [
    "base = \"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\images\\\\Selected\\\\\"\n",
    "for i, rows in df.iterrows():\n",
    "\n",
    "    x,y = rows[0].split(\".\")\n",
    "    a,b,c,d = x.split(\"_\")\n",
    "    folder_name = a + \"_\" + b + \"_\" + c + \"\\\\\"\n",
    "    file_name = d + \".\" + y\n",
    "    file_location = base + folder_name + file_name\n",
    "    os.chdir(base + folder_name)\n",
    "    \n",
    "    if rows[\"Train_Val_Test\"] == 3 and rows[\"Possibly_noisy\"] == 0:\n",
    "        #print(i)\n",
    "        if df[\"Image_size\"][i].split(\",\")[0] != \"512\":\n",
    "            print(i)\n",
    "            im = Image.open(file_name)\n",
    "            im2 = im.resize((512, 512))\n",
    "            im2.save(\"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\images\\\\test\\\\images\\\\\" + rows[0])\n",
    "        else:\n",
    "            to_file = str(\"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\images\\\\test\\\\images\\\\\" + rows[0])\n",
    "            shutil.copy2(file_location, to_file)      \n",
    "        \n",
    "    elif rows[\"Possibly_noisy\"] == 0:\n",
    "        \n",
    "        if df[\"Image_size\"][i].split(\",\")[0] != \"512\":\n",
    "            print(i)\n",
    "            im = Image.open(file_name)\n",
    "            im2 = im.resize((512, 512))\n",
    "            im2.save(\"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\images\\\\train\\\\images\\\\\" + rows[0])\n",
    "        else:\n",
    "            to_file = str(\"C:\\\\Temp\\\\nitish\\\\Tensorflow\\\\workspace\\\\training_demo\\\\images\\\\train\\\\images\\\\\" + rows[0])\n",
    "            shutil.copy2(file_location, to_file)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
